{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example of when the model is fed two features. In the training data, $y = sin(X_1)$. $X_2$ has no correlation to $y$ whatsoever, and is just random numbers. We are testing to see how the model degrades if one of the features contains no information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required libraries. `numpy` is used to allow us to manipulate arrays with efficiency. `pandas` gives us access to Panda Dataframes which are the preferred way of storing our data. `matplotlib.pyplot` lets us plot graphs with our data. `twinlab` is the main library we are using. Some of the libraries are renamed using `as` for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the top of this cell we define the name of our dataset and model.\n",
    "\n",
    "Next, we define the training data:\n",
    "- $X_1$ is an array of values between 0 and 1.\n",
    "- $X_2$ creates an array of 10 random numbers between 0 and 1. \n",
    "- $y$ is $sin(X_1)$ and has no dependency on $X_2$ whatsoever. \n",
    "\n",
    "At the bottom of the cell we put these arrays into a Pandas dataframe with the corresponding coloumn headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"second_random_input.csv\"\n",
    "campaign_id = \"second_random_input\"\n",
    "\n",
    "#Training Data\n",
    "X1 = np.array([\n",
    "    0.6964691855978616,\n",
    "    0.28613933495037946,\n",
    "    0.2268514535642031, \n",
    "    0.5513147690828912, \n",
    "    0.7194689697855631, \n",
    "    0.42310646012446096, \n",
    "    0.9807641983846155, \n",
    "    0.6848297385848633, \n",
    "    0.48093190148436094, \n",
    "    0.3921175181941505\n",
    "])\n",
    "X2 = np.random.rand(10)\n",
    "y = np.sin(X1*2.*np.pi) + np.random.normal(0, 0.05, 10)\n",
    "\n",
    "train_data = pd.DataFrame({'X1': X1, 'X2':X2, 'y': y })\n",
    "print(train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we set the parameters to be used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines parameters for our prediction\n",
    "prediction_params = {\n",
    "    \"filename\": dataset_id,\n",
    "    \"inputs\" : [\"X1\", \"X2\"],\n",
    "    \"outputs\": [\"y\"],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates our input values for the model to predict outputs for. \n",
    "- The $X_1$ values are 101 equally spaced numbers between 0 and 1. \n",
    "- The $X_2$ values are 101 random values between 0 and 1. \n",
    "\n",
    "We now create a Pandas Dataframe with the data and corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {\n",
    "    \"X1\": np.linspace(0, 1, 101),\n",
    "    \"X2\": np.random.rand(101)\n",
    "}\n",
    "\n",
    "prediction_inputs = pd.DataFrame(input_dict)\n",
    "print(prediction_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now upload the training data (the already set values of $X_1, X_2$ and $y$) to the twinLab cloud.\n",
    "\n",
    "Whenever `verbose = true` is an argument, the function returns information about what it is doing to the user. This generates the grey text below the cells when they are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.upload_dataset(train_data, dataset_name=dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tl.list_datasets()` lets us check if the dataset we uploaded is in the right place.\n",
    "`tl.query_dataset()` lets us view statistics about the data in our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.list_datasets(verbose=True)\n",
    "tl.query_dataset(dataset_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell trains the model on the dataset we provided, and using the parameters we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.train_campaign(prediction_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply lists the current models on the twinlab cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.list_campaigns(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays information about the model we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.query_campaign(campaign_id, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ingest $X_1$ and $X_2$ values and, based on the training data, make predictions for the corresponding $y$ value. `df_mean` is the mean value that the model predicts, while `df_std` an estimate of the uncertainty of the model around the `df_mean value`. There is around a $68$ chance that values lie within df_std of df_mean, which rises to $95$ within `2*df_std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean, df_std = tl.predict_campaign(prediction_inputs, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we first plot on a graph the $X_1$ against $y$, then $X_2$ against $y$. \n",
    "- The black dots on the graph are the training data we gave it. \n",
    "- The darkest blue line in the graph is the `df_mean` value.\n",
    "- The blue sections either side represent the range of uncertainty in the `df_mean` value.\n",
    "\n",
    "On the first graph ($X_1$ against $y$), the model has become more uncertain about its predictions of $y$ because of the introduction of $X_2$\n",
    "On the second graph, we can see there is no correlation between $X_2$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "for X, Xlabel in zip([\"X1\", \"X2\"], [\"$X_1$\", \"$X_2$\"]):\n",
    "# Plot results\n",
    "    grid = prediction_inputs[X]\n",
    "    mean = df_mean[\"y\"]\n",
    "    err = df_std[\"y\"]\n",
    "    if plot_model_bands:\n",
    "        label = \"Model prediction\"\n",
    "        plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "        for isig, nsig in enumerate(nsigs):\n",
    "            plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "    if plot_model_mean:\n",
    "        label = \"Model prediction\" if not plot_model_bands else None\n",
    "        plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "    if plot_training_data:\n",
    "        plt.plot(train_data[X], train_data[\"y\"], \".\", color=\"black\", label=\"Training data\")\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.xlabel(Xlabel)\n",
    "    plt.ylabel(\"$y$\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaign and dataset (if desired)\n",
    "tl.delete_campaign(campaign_id, verbose=True)\n",
    "tl.delete_dataset(dataset_id, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-cloud-IBHCqXSr-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
