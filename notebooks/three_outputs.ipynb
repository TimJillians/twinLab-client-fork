{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notbook we are testing how the model responds when it is asked to produce three outputs from one input. One of the outputs will be equal to the input, and another the quotient of the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required libraries. `numpy` is used to allow us to manipulate arrays with efficiency. `pandas` gives us access to Panda Dataframes which are the preferred way of storing our data. `matplotlib.pyplot` lets us plot graphs with our data. `twinlab` is the main library we are using. The libraries are renamed using `as` for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project imports\n",
    "import twinlab as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we train the model on our training data. We also set `n` to the number of items of training data we want.\n",
    "- We give it the first output $y_1$ which is an array of `n` length filled with float numbers between 0 and 1.\n",
    "- We give it the third output $y_3$ which is an array of `n` evenly spaced numbers between 0 and 1.\n",
    "- We define the second output $y_2$ as an array, where each element is the corresponding $y_3$ element divided by the corresponding $y_1$ element.\n",
    "- The only input is $X$, which is equal to $y_3$ plus a small amount of random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"three_outputs.csv\"\n",
    "campaign_id = \"three_outputs\"\n",
    "\n",
    "#Training Data\n",
    "n = 100\n",
    "y1 = np.random.rand(n)\n",
    "y3 = np.linspace(0, 1, n) \n",
    "y2 = y3/y1\n",
    "X = y3 + np.random.normal(0, 0.05, n)\n",
    "\n",
    "train_data = pd.DataFrame({'X': X, 'y1': y1, 'y2':y2, \"y3\":y3})\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we set the parameters we are going to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines parameters for our prediction\n",
    "prediction_params = {\n",
    "    \"filename\": dataset_id,\n",
    "    \"inputs\" : [\"X\"],\n",
    "    \"outputs\": [\"y1\", \"y2\", \"y3\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now upload the training data to the twinLab cloud.\n",
    "\n",
    "Whenever `verbose = true` is an argument, the function returns information about what it is doing to the user. This generates the grey text below the cells when they are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.upload_dataset(train_data, dataset_name=dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tl.list_datasets()` lets us check if the dataset we uploaded is in the right place.\n",
    "`tl.query_dataset()` lets us view statistics about the data in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.list_datasets(verbose=True)\n",
    "tl.query_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell trains the model on the dataset we provided, and within the parameters we provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.train_campaign(prediction_params, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply lists the current models on the twinlab cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.list_campaigns(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This displays information about the model we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tl.query_campaign(campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates the input data we are going to give to the model for it to predict the three outputs of. \n",
    "The data is currently 1001 (defined by `num_predictions`) evenly spaced numbers between 0 and 1.\n",
    "\n",
    "We also put them in a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_predictions = 1001\n",
    "input_dict = {\n",
    "    \"X\": np.linspace(0., 1., num_predictions).tolist()\n",
    "}\n",
    "\n",
    "prediction_inputs = pd.DataFrame(input_dict)\n",
    "print(prediction_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then give these numbers to the model, and it generates what it thinks the three outputs should be. `df_mean` is the value it predicts. `df_std` is how uncertain the model is about that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_inputs)\n",
    "df_mean, df_std = tl.predict_campaign(prediction_inputs, campaign_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the data on 3 graphs - one for X against $y_1$, one for X against $y_2$, and one for X against $y_3$.\n",
    "- The black dots on the graph are the training data we gave it. \n",
    "- The darkest blue line in the graph is the `df_mean` value.\n",
    "- The blue sections either side represent the range of uncertainty in the `df_mean` value.\n",
    "\n",
    "$y_1$ settles to around a value of 0.5.\n",
    "$y_2$'s average will increase the more numbers the model predicts, currently at around 2 - but with more data it would increase.\n",
    "$y_2$ also has some enourmously high values which occur whenever $y_1$ is a very tiny number, so the result of the division is very high. \n",
    "The third graph shows the model is good at predicting $y_3$, because the training data shows it is the same as the $X$ value it is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot parameters\n",
    "nsigs = [1, 2]\n",
    "color = \"blue\"\n",
    "alpha = 0.5\n",
    "plot_training_data = True\n",
    "plot_model_mean = True\n",
    "plot_model_bands = True\n",
    "\n",
    "# Plot results\n",
    "for Y, Ylabel in zip([\"y1\", \"y2\", \"y3\"], [\"$y_1$\", \"$y_2$\", \"$y_3$\"]):\n",
    "    grid = prediction_inputs[\"X\"]\n",
    "    mean = df_mean[Y]\n",
    "    err = df_std[Y]\n",
    "    if plot_model_bands:\n",
    "        label = \"Model prediction\"\n",
    "        plt.fill_between(grid, np.nan, np.nan, lw=0, color=color, alpha=alpha, label=label)\n",
    "        for isig, nsig in enumerate(nsigs):\n",
    "            plt.fill_between(grid, mean-nsig*err, mean+nsig*err, lw=0, color=color, alpha=alpha/(isig+1))\n",
    "    if plot_model_mean:\n",
    "        label = \"Model prediction\" if not plot_model_bands else None\n",
    "        plt.plot(grid, mean, color=color, alpha=alpha, label=label)\n",
    "    if plot_training_data:\n",
    "        plt.plot(train_data[\"X\"], train_data[Y], \".\", color=\"black\", label=\"Training data\")\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.xlabel(\"$X$\")\n",
    "    plt.ylabel(Ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "print(prediction_inputs)\n",
    "print(df_mean)\n",
    "print(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally remove our dataset and trained model from the twinlab cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete campaign and dataset (if desired)\n",
    "tl.delete_campaign(campaign_id, verbose=True)\n",
    "tl.delete_dataset(dataset_id, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that it is very difficult to determine two numbers just based on their quotient, as there are many values they can take."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinlab-cloud-IBHCqXSr-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
